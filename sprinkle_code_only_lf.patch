--- a/scripts/curriculum_gen/config.py
+++ b/scripts/curriculum_gen/config.py
@@ -1,230 +1,276 @@
-from __future__ import annotations
-
-import copy
-import json
-from pathlib import Path
-from typing import Any
-
-
-"""
-Config schema (JSON)
-
-curriculum_config/global.json
-{
-  "defaults": {
-    "task": ["..."],
-    "checklist": ["..."],
-    "hints": ["..."],
-    "docs_links": [{"label": "...", "url": "..."}],
-    "hints_block": {"enabled": true},
-
-    // optional additive list semantics:
-    "task_append": ["..."],
-    "checklist_append": ["..."],
-    "hints_append": ["..."],
-    "docs_links_append": [{"label": "...", "url": "..."}]
-  }
-}
-
-curriculum_config/tier-XX.json
-{
-  "tier_defaults": { ...same shape as defaults... },
-  "files": {
-    "<day-slug>": { ...same shape as defaults... }
-  }
-}
-
-Merge semantics:
-- dicts deep-merge
-- lists replace
-- *_append keys append onto the base list (after deep-copy)
-"""
-
-
-_ALLOWED_TIER_ROOT_KEYS = {"tier_defaults", "files"}
-_ALLOWED_GLOBAL_ROOT_KEYS = {"defaults", "site"}
-
-_ALLOWED_SITE_KEYS = {"max_tier"}
-
-_ALLOWED_SECTION_KEYS = {
-    "task",
-    "checklist",
-    "hints",
-    "docs_links",
-    "hints_block",
-    "task_append",
-    "checklist_append",
-    "hints_append",
-    "docs_links_append",
-}
-
-
-def _read_json(path: Path) -> dict[str, Any]:
-    if not path.exists():
-        return {}
-    try:
-        return json.loads(path.read_text(encoding="utf-8"))
-    except json.JSONDecodeError as e:
-        raise ValueError(f"Bad JSON in {path}") from e
-
-
-def _validate_section_obj(obj: dict[str, Any], ctx: str) -> None:
-    extra = set(obj.keys()) - _ALLOWED_SECTION_KEYS
-    if extra:
-        raise ValueError(f"Unknown keys in {ctx}: {sorted(extra)}")
-
-    for k in ("task", "task_append", "checklist", "checklist_append", "hints", "hints_append"):
-        if k in obj and obj[k] is not None:
-            if not isinstance(obj[k], list) or not all(isinstance(x, str) for x in obj[k]):
-                raise ValueError(f"{ctx}.{k} must be a list[str]")
-
-    for k in ("docs_links", "docs_links_append"):
-        if k in obj and obj[k] is not None:
-            if not isinstance(obj[k], list):
-                raise ValueError(f"{ctx}.{k} must be a list")
-            for i, it in enumerate(obj[k]):
-                if isinstance(it, dict):
-                    if not isinstance(it.get("label"), str) or not isinstance(it.get("url"), str):
-                        raise ValueError(f"{ctx}.{k}[{i}] must have str label/url")
-                elif isinstance(it, (list, tuple)):
-                    if len(it) != 2 or not isinstance(it[0], str) or not isinstance(it[1], str):
-                        raise ValueError(f"{ctx}.{k}[{i}] must be [label, url]")
-                else:
-                    raise ValueError(f"{ctx}.{k}[{i}] must be an object with label/url")
-
-    if "hints_block" in obj and obj["hints_block"] is not None:
-        hb = obj["hints_block"]
-        if not isinstance(hb, dict):
-            raise ValueError(f"{ctx}.hints_block must be an object")
-        if "enabled" in hb and not isinstance(hb["enabled"], bool):
-            raise ValueError(f"{ctx}.hints_block.enabled must be a bool")
-
-
-def _validate_site_obj(obj: dict[str, Any], ctx: str) -> None:
-    extra = set(obj.keys()) - _ALLOWED_SITE_KEYS
-    if extra:
-        raise ValueError(f"Unknown keys in {ctx}: {sorted(extra)}")
-
-    if "max_tier" in obj and obj["max_tier"] is not None:
-        mt = obj["max_tier"]
-        if not isinstance(mt, int) or mt < 1:
-            raise ValueError(f"{ctx}.max_tier must be an int >= 1")
-
-
-def merge_section(base: dict[str, Any], override: dict[str, Any]) -> dict[str, Any]:
-    """
-    Deep-merge dicts.
-    - dict + dict merges recursively
-    - lists replace
-    - supports *_append keys to append list items
-    """
-    out = copy.deepcopy(base)
-
-    # handle *_append first
-    for k, v in override.items():
-        if not k.endswith("_append"):
-            continue
-        target = k[: -len("_append")]
-        if v is None:
-            continue
-        prev = out.get(target)
-        if prev is None:
-            prev = []
-        if not isinstance(prev, list) or not isinstance(v, list):
-            raise ValueError(f"Cannot append non-lists via {k}")
-        out[target] = prev + v
-
-    # normal override/deep merge
-    for k, v in override.items():
-        if k.endswith("_append"):
-            continue
-        if isinstance(v, dict) and isinstance(out.get(k), dict):
-            out[k] = merge_section(out[k], v)  # type: ignore[arg-type]
-        else:
-            out[k] = copy.deepcopy(v)
-
-    return out
-
-
-def load_global_defaults(config_root: Path) -> dict[str, Any]:
-    """
-    Load curriculum_config/global.json defaults.
-
-    Returns the inner "defaults" object (validated), or {} if missing.
-    """
-    cfg = _read_json(config_root / "global.json")
-    if not cfg:
-        return {}
-
-    extra = set(cfg.keys()) - _ALLOWED_GLOBAL_ROOT_KEYS
-    if extra:
-        raise ValueError(f"Unknown keys in global.json: {sorted(extra)}")
-
-    defaults = cfg.get("defaults", {})
-    if not isinstance(defaults, dict):
-        raise ValueError("global.json.defaults must be an object")
-
-    _validate_section_obj(defaults, "global.json.defaults")
-    return defaults
-
-
-def load_site_config(config_root: Path) -> dict[str, Any]:
-    """Load curriculum_config/global.json site settings.
-
-    Returns the inner "site" object (validated), or {} if missing.
-
-    Supported keys:
-      - max_tier: int >= 1
-    """
-    cfg = _read_json(config_root / "global.json")
-    if not cfg:
-        return {}
-
-    extra = set(cfg.keys()) - _ALLOWED_GLOBAL_ROOT_KEYS
-    if extra:
-        raise ValueError(f"Unknown keys in global.json: {sorted(extra)}")
-
-    site = cfg.get("site", {})
-    if site is None:
-        return {}
-    if not isinstance(site, dict):
-        raise ValueError("global.json.site must be an object")
-
-    _validate_site_obj(site, "global.json.site")
-    return site
-
-
-def load_tier_config(config_root: Path, tier_n: int) -> dict[str, Any]:
-    """
-    Load curriculum_config/tier-XX.json for the given tier.
-
-    Returns:
-      {"tier_defaults": dict, "files": dict}
-    """
-    path = config_root / f"tier-{tier_n:02d}.json"
-    cfg = _read_json(path)
-    if not cfg:
-        return {"tier_defaults": {}, "files": {}}
-
-    extra = set(cfg.keys()) - _ALLOWED_TIER_ROOT_KEYS
-    if extra:
-        raise ValueError(f"Unknown keys in {path.name}: {sorted(extra)}")
-
-    tier_defaults = cfg.get("tier_defaults", {})
-    files = cfg.get("files", {})
-
-    if not isinstance(tier_defaults, dict):
-        raise ValueError(f"{path.name}.tier_defaults must be an object")
-    if not isinstance(files, dict):
-        raise ValueError(f"{path.name}.files must be an object")
-
-    _validate_section_obj(tier_defaults, f"{path.name}.tier_defaults")
-
-    for slug, overrides in files.items():
-        if not isinstance(slug, str):
-            raise ValueError(f"{path.name}.files keys must be strings")
-        if not isinstance(overrides, dict):
-            raise ValueError(f"{path.name}.files[{slug}] must be an object")
-        _validate_section_obj(overrides, f"{path.name}.files[{slug}]")
-
-    return {"tier_defaults": tier_defaults, "files": files}
+from __future__ import annotations
+
+import copy
+import json
+from pathlib import Path
+from typing import Any
+
+
+"""
+Config schema (JSON)
+
+curriculum_config/global.json
+{
+  "defaults": {
+    "task": ["..."],
+    "checklist": ["..."],
+    "hints": ["..."],
+    "docs_links": [{"label": "...", "url": "..."}],
+    "example_run": ["..."],
+    "solution_block": {
+      "enabled": true,
+      "summary": "Show solution",
+      "language": "python",
+      "filename": "main.py",
+      "text": ["Optional intro line"],
+      "code": ["print('hello')"]
+    },
+    "hints_block": {"enabled": true},
+
+    // optional additive list semantics:
+    "task_append": ["..."],
+    "checklist_append": ["..."],
+    "hints_append": ["..."],
+    "docs_links_append": [{"label": "...", "url": "..."}],
+    "example_run_append": ["..."]
+  }
+}
+
+curriculum_config/tier-XX.json
+{
+  "tier_defaults": { ...same shape as defaults... },
+  "files": {
+    "<day-slug>": { ...same shape as defaults... }
+  }
+}
+
+Merge semantics:
+- dicts deep-merge
+- lists replace
+- *_append keys append onto the base list (after deep-copy)
+"""
+
+
+_ALLOWED_TIER_ROOT_KEYS = {"tier_defaults", "files"}
+_ALLOWED_GLOBAL_ROOT_KEYS = {"defaults", "site"}
+
+_ALLOWED_SITE_KEYS = {"max_tier"}
+
+_ALLOWED_SECTION_KEYS = {
+    "task",
+    "checklist",
+    "hints",
+    "docs_links",
+    "example_run",
+    "solution_block",
+    "hints_block",
+    "task_append",
+    "checklist_append",
+    "hints_append",
+    "docs_links_append",
+    "example_run_append",
+}
+
+
+def _read_json(path: Path) -> dict[str, Any]:
+    if not path.exists():
+        return {}
+    try:
+        return json.loads(path.read_text(encoding="utf-8"))
+    except json.JSONDecodeError as e:
+        raise ValueError(f"Bad JSON in {path}") from e
+
+
+def _validate_section_obj(obj: dict[str, Any], ctx: str) -> None:
+    extra = set(obj.keys()) - _ALLOWED_SECTION_KEYS
+    if extra:
+        raise ValueError(f"Unknown keys in {ctx}: {sorted(extra)}")
+
+    for k in (
+        "task",
+        "task_append",
+        "checklist",
+        "checklist_append",
+        "hints",
+        "hints_append",
+        "example_run",
+        "example_run_append",
+    ):
+        if k in obj and obj[k] is not None:
+            if not isinstance(obj[k], list) or not all(isinstance(x, str) for x in obj[k]):
+                raise ValueError(f"{ctx}.{k} must be a list[str]")
+
+    for k in ("docs_links", "docs_links_append"):
+        if k in obj and obj[k] is not None:
+            if not isinstance(obj[k], list):
+                raise ValueError(f"{ctx}.{k} must be a list")
+            for i, it in enumerate(obj[k]):
+                if isinstance(it, dict):
+                    if not isinstance(it.get("label"), str) or not isinstance(it.get("url"), str):
+                        raise ValueError(f"{ctx}.{k}[{i}] must have str label/url")
+                elif isinstance(it, (list, tuple)):
+                    if len(it) != 2 or not isinstance(it[0], str) or not isinstance(it[1], str):
+                        raise ValueError(f"{ctx}.{k}[{i}] must be [label, url]")
+                else:
+                    raise ValueError(f"{ctx}.{k}[{i}] must be an object with label/url")
+
+    if "hints_block" in obj and obj["hints_block"] is not None:
+        hb = obj["hints_block"]
+        if not isinstance(hb, dict):
+            raise ValueError(f"{ctx}.hints_block must be an object")
+        if "enabled" in hb and not isinstance(hb["enabled"], bool):
+            raise ValueError(f"{ctx}.hints_block.enabled must be a bool")
+
+    if "solution_block" in obj and obj["solution_block"] is not None:
+        sb = obj["solution_block"]
+        if not isinstance(sb, dict):
+            raise ValueError(f"{ctx}.solution_block must be an object")
+
+        allowed_sb_keys = {"enabled", "summary", "language", "filename", "text", "code"}
+        extra_sb = set(sb.keys()) - allowed_sb_keys
+        if extra_sb:
+            raise ValueError(f"Unknown keys in {ctx}.solution_block: {sorted(extra_sb)}")
+
+        if "enabled" in sb and not isinstance(sb["enabled"], bool):
+            raise ValueError(f"{ctx}.solution_block.enabled must be a bool")
+        if "summary" in sb and sb["summary"] is not None and not isinstance(sb["summary"], str):
+            raise ValueError(f"{ctx}.solution_block.summary must be a str")
+        if "language" in sb and sb["language"] is not None and not isinstance(sb["language"], str):
+            raise ValueError(f"{ctx}.solution_block.language must be a str")
+        if "filename" in sb and sb["filename"] is not None and not isinstance(sb["filename"], str):
+            raise ValueError(f"{ctx}.solution_block.filename must be a str")
+
+        for k in ("text", "code"):
+            if k in sb and sb[k] is not None:
+                if not isinstance(sb[k], list) or not all(isinstance(x, str) for x in sb[k]):
+                    raise ValueError(f"{ctx}.solution_block.{k} must be a list[str]")
+
+
+def _validate_site_obj(obj: dict[str, Any], ctx: str) -> None:
+    extra = set(obj.keys()) - _ALLOWED_SITE_KEYS
+    if extra:
+        raise ValueError(f"Unknown keys in {ctx}: {sorted(extra)}")
+
+    if "max_tier" in obj and obj["max_tier"] is not None:
+        mt = obj["max_tier"]
+        if not isinstance(mt, int) or mt < 1:
+            raise ValueError(f"{ctx}.max_tier must be an int >= 1")
+
+
+def merge_section(base: dict[str, Any], override: dict[str, Any]) -> dict[str, Any]:
+    """
+    Deep-merge dicts.
+    - dict + dict merges recursively
+    - lists replace
+    - supports *_append keys to append list items
+    """
+    out = copy.deepcopy(base)
+
+    # handle *_append first
+    for k, v in override.items():
+        if not k.endswith("_append"):
+            continue
+        target = k[: -len("_append")]
+        if v is None:
+            continue
+        prev = out.get(target)
+        if prev is None:
+            prev = []
+        if not isinstance(prev, list) or not isinstance(v, list):
+            raise ValueError(f"Cannot append non-lists via {k}")
+        out[target] = prev + v
+
+    # normal override/deep merge
+    for k, v in override.items():
+        if k.endswith("_append"):
+            continue
+        if isinstance(v, dict) and isinstance(out.get(k), dict):
+            out[k] = merge_section(out[k], v)  # type: ignore[arg-type]
+        else:
+            out[k] = copy.deepcopy(v)
+
+    return out
+
+
+def load_global_defaults(config_root: Path) -> dict[str, Any]:
+    """
+    Load curriculum_config/global.json defaults.
+
+    Returns the inner "defaults" object (validated), or {} if missing.
+    """
+    cfg = _read_json(config_root / "global.json")
+    if not cfg:
+        return {}
+
+    extra = set(cfg.keys()) - _ALLOWED_GLOBAL_ROOT_KEYS
+    if extra:
+        raise ValueError(f"Unknown keys in global.json: {sorted(extra)}")
+
+    defaults = cfg.get("defaults", {})
+    if not isinstance(defaults, dict):
+        raise ValueError("global.json.defaults must be an object")
+
+    _validate_section_obj(defaults, "global.json.defaults")
+    return defaults
+
+
+def load_site_config(config_root: Path) -> dict[str, Any]:
+    """Load curriculum_config/global.json site settings.
+
+    Returns the inner "site" object (validated), or {} if missing.
+
+    Supported keys:
+      - max_tier: int >= 1
+    """
+    cfg = _read_json(config_root / "global.json")
+    if not cfg:
+        return {}
+
+    extra = set(cfg.keys()) - _ALLOWED_GLOBAL_ROOT_KEYS
+    if extra:
+        raise ValueError(f"Unknown keys in global.json: {sorted(extra)}")
+
+    site = cfg.get("site", {})
+    if site is None:
+        return {}
+    if not isinstance(site, dict):
+        raise ValueError("global.json.site must be an object")
+
+    _validate_site_obj(site, "global.json.site")
+    return site
+
+
+def load_tier_config(config_root: Path, tier_n: int) -> dict[str, Any]:
+    """
+    Load curriculum_config/tier-XX.json for the given tier.
+
+    Returns:
+      {"tier_defaults": dict, "files": dict}
+    """
+    path = config_root / f"tier-{tier_n:02d}.json"
+    cfg = _read_json(path)
+    if not cfg:
+        return {"tier_defaults": {}, "files": {}}
+
+    extra = set(cfg.keys()) - _ALLOWED_TIER_ROOT_KEYS
+    if extra:
+        raise ValueError(f"Unknown keys in {path.name}: {sorted(extra)}")
+
+    tier_defaults = cfg.get("tier_defaults", {})
+    files = cfg.get("files", {})
+
+    if not isinstance(tier_defaults, dict):
+        raise ValueError(f"{path.name}.tier_defaults must be an object")
+    if not isinstance(files, dict):
+        raise ValueError(f"{path.name}.files must be an object")
+
+    _validate_section_obj(tier_defaults, f"{path.name}.tier_defaults")
+
+    for slug, overrides in files.items():
+        if not isinstance(slug, str):
+            raise ValueError(f"{path.name}.files keys must be strings")
+        if not isinstance(overrides, dict):
+            raise ValueError(f"{path.name}.files[{slug}] must be an object")
+        _validate_section_obj(overrides, f"{path.name}.files[{slug}]")
+
+    return {"tier_defaults": tier_defaults, "files": files}
--- a/scripts/curriculum_gen/generator.py
+++ b/scripts/curriculum_gen/generator.py
@@ -1,205 +1,251 @@
-from __future__ import annotations
-
-import json
-import re
-from pathlib import Path
-from typing import Any
-
-from .config import load_global_defaults, load_site_config, load_tier_config, merge_section
-from .links import links_for_tier
-from .markdown import (
-    normalize_newlines,
-    remove_section,
-    render_bullets,
-    render_checklist,
-    render_docs_links,
-    replace_or_append_section,
-    section_body_from_lines,
-    upsert_frontmatter,
-)
-from .parsing import parse_curriculum, slugify
-from .raw_curriculum import RAW
-
-
-def write_file(path: Path, text: str) -> None:
-    """Atomic-enough for docs generation: ensure parent exists then write UTF-8."""
-    path.parent.mkdir(parents=True, exist_ok=True)
-    path.write_text(text, encoding="utf-8")
-
-
-def generate(*, repo_root: Path) -> Path:
-    """
-    Generate/refresh curriculum docs under {repo_root}/docs/curriculum.
-
-    Integration contract (filesystem):
-      - reads RAW (baked-in)
-      - reads config from {repo_root}/curriculum_config/
-          - global.json (optional)
-          - tier-XX.json (optional)
-      - writes docs to {repo_root}/docs/curriculum/
-
-    Returns:
-        Path to the docs_root folder.
-    """
-    docs_root = repo_root / "docs" / "curriculum"
-    config_root = repo_root / "curriculum_config"
-
-    tiers = parse_curriculum(RAW)
-    global_defaults = load_global_defaults(config_root)
-    site_cfg = load_site_config(config_root)
-    max_public_tier = site_cfg.get("max_tier")
-
-    # Root category + landing page
-    write_file(
-        docs_root / "_category_.json",
-        json.dumps(
-            {
-                "label": "Curriculum",
-                "position": 1,
-                "link": {
-                    "type": "generated-index",
-                    "title": "Curriculum",
-                    "description": "Click a tier to start. Each tier page lists the days.",
-                },
-            },
-            indent=2,
-        )
-        + "\n",
-    )
-
-    landing = [
-        "# Curriculum\n",
-        "\n",
-        "Difficulty:\n",
-        "- ! üíö Easy !\n",
-        "- ! üíõ Medium !\n",
-        "- ! ‚ù§Ô∏è‚Äçüî• Hard !\n",
-        "- ! üíú Boss !\n",
-        "\n",
-        "Unlock the next tier by completing all the units!\n",
-        "\n",
-        "## Tiers\n",
-    ]
-
-    available = 0
-    locked = 0
-
-    for t in tiers:
-        tier_folder = f"tier-{t.n:02d}-{slugify(t.name)}"
-
-        is_public = not isinstance(max_public_tier, int) or t.n <= max_public_tier
-        if is_public:
-            available += 1
-            landing.append(f"- ‚úÖ [TIER {t.n} ‚Äî {t.name}](/curriculum/{tier_folder})\n")
-
-    landing.insert(
-        landing.index("## Tiers\n"),
-        f"\n**Available now:** {available} tier(s)"
-        + (f" ‚Ä¢ **Locked:** {locked}" if locked else "")
-        + "\n",
-    )
-
-    write_file(docs_root / "index.mdx", "".join(landing) + "\n")
-        
-    # Tiers + days
-    for t in tiers:
-        tier_cfg = load_tier_config(config_root, t.n)
-        tier_defaults: dict[str, Any] = tier_cfg["tier_defaults"]
-        file_overrides: dict[str, Any] = tier_cfg["files"]
-
-        expected_slugs = {slugify(d.title) for d in t.days}
-        extra = set(file_overrides.keys()) - expected_slugs
-        if extra:
-            raise ValueError(
-                f"{config_root / f'tier-{t.n:02d}.json'} contains unknown slugs: {sorted(extra)}"
-            )
-
-        tier_folder = docs_root / f"tier-{t.n:02d}-{slugify(t.name)}"
-        tier_index_slug = f"/curriculum/{tier_folder.name}"
-
-        write_file(
-            tier_folder / "_category_.json",
-            json.dumps(
-                {
-                    "label": f"TIER {t.n} ‚Äî {t.name}",
-                    "position": t.n,
-                    "link": {
-                        "type": "generated-index",
-                        "slug": tier_index_slug,
-                        "title": f"TIER {t.n} ‚Äî {t.name}",
-                        "description": "Do tasks ‚Üí do boss.",
-                    },
-                },
-                indent=2,
-            )
-            + "\n",
-        )
-
-        for i, d in enumerate(t.days, start=1):
-            slug = slugify(d.title)
-            filename = f"{slug}.md"
-
-            sidebar_label = f"{d.emoji} {d.title}"
-            title = f"{d.emoji} ‚Äî {d.title}"
-
-            effective = merge_section(global_defaults, tier_defaults)
-            effective = merge_section(effective, file_overrides.get(slug, {}))
-
-            # If a block is None or an empty list, we treat it as "do not render".
-            task = effective.get("task")
-            checklist = effective.get(
-                "checklist",
-                ["Works", "Cleaned up", "(Optional) 1 upgrade / stretch"],
-            )
-
-            hints_block = effective.get("hints_block", {})
-            hints_enabled = bool(hints_block.get("enabled", False))
-            hints = effective.get("hints", []) if hints_enabled else []
-
-            if "docs_links" in effective:
-                docs_links = effective["docs_links"]
-            else:
-                docs_links = links_for_tier(t.n)
-
-            path = tier_folder / filename
-            existing = path.read_text(encoding="utf-8") if path.exists() else ""
-            existing = normalize_newlines(existing)
-
-            md = upsert_frontmatter(
-                existing,
-                title=title,
-                sidebar_label=sidebar_label,
-                sidebar_position=i,
-            )
-
-            # Task / Checklist are optional: if they resolve to empty/None, remove the section entirely.
-            if isinstance(task, list) and any(x.strip() for x in task):
-                md = replace_or_append_section(md, "Task", section_body_from_lines(render_bullets(task)))
-            else:
-                md = remove_section(md, "Task")
-
-            if isinstance(checklist, list) and any(x.strip() for x in checklist):
-                md = replace_or_append_section(
-                    md, "Checklist", section_body_from_lines(render_checklist(checklist))
-                )
-            else:
-                md = remove_section(md, "Checklist")
-
-            if hints_enabled:
-                md = replace_or_append_section(md, "Hints", section_body_from_lines(render_bullets(hints)))
-            else:
-                md = remove_section(md, "Hints")
-
-            if docs_links:
-                md = replace_or_append_section(
-                    md, "Docs / Tutorials", section_body_from_lines(render_docs_links(docs_links))
-                )
-            else:
-                md = remove_section(md, "Docs / Tutorials")
-
-            # Final formatting pass: prevent runaway blank lines from accumulating
-            # after multiple generations.
-            md = re.sub(r"\n{3,}", "\n\n", md).strip("\n") + "\n"
-            write_file(path, md)
-
+from __future__ import annotations
+
+import json
+import re
+from pathlib import Path
+from typing import Any
+
+from .config import load_global_defaults, load_site_config, load_tier_config, merge_section
+from .links import links_for_tier
+from .markdown import (
+    normalize_newlines,
+    remove_section,
+    render_bullets,
+    render_checklist,
+    render_docs_links,
+    replace_or_append_section,
+    section_body_from_lines,
+    upsert_frontmatter,
+)
+from .parsing import parse_curriculum, slugify
+from .raw_curriculum import RAW
+
+
+def write_file(path: Path, text: str) -> None:
+    """Atomic-enough for docs generation: ensure parent exists then write UTF-8."""
+    path.parent.mkdir(parents=True, exist_ok=True)
+    path.write_text(text, encoding="utf-8")
+
+
+def generate(*, repo_root: Path) -> Path:
+    """
+    Generate/refresh curriculum docs under {repo_root}/docs/curriculum.
+
+    Integration contract (filesystem):
+      - reads RAW (baked-in)
+      - reads config from {repo_root}/curriculum_config/
+          - global.json (optional)
+          - tier-XX.json (optional)
+      - writes docs to {repo_root}/docs/curriculum/
+
+    Returns:
+        Path to the docs_root folder.
+    """
+    docs_root = repo_root / "docs" / "curriculum"
+    config_root = repo_root / "curriculum_config"
+
+    tiers = parse_curriculum(RAW)
+    global_defaults = load_global_defaults(config_root)
+    site_cfg = load_site_config(config_root)
+    max_public_tier = site_cfg.get("max_tier")
+
+    # Root category + landing page
+    write_file(
+        docs_root / "_category_.json",
+        json.dumps(
+            {
+                "label": "Curriculum",
+                "position": 1,
+                "link": {
+                    "type": "generated-index",
+                    "title": "Curriculum",
+                    "description": "Click a tier to start. Each tier page lists the days.",
+                },
+            },
+            indent=2,
+        )
+        + "\n",
+    )
+
+    landing = [
+        "# Curriculum\n",
+        "\n",
+        "Difficulty:\n",
+        "- ! üíö Easy !\n",
+        "- ! üíõ Medium !\n",
+        "- ! ‚ù§Ô∏è‚Äçüî• Hard !\n",
+        "- ! üíú Boss !\n",
+        "\n",
+        "Unlock the next tier by completing all the units!\n",
+        "\n",
+        "## Tiers\n",
+    ]
+
+    available = 0
+    locked = 0
+
+    for t in tiers:
+        tier_folder = f"tier-{t.n:02d}-{slugify(t.name)}"
+
+        is_public = not isinstance(max_public_tier, int) or t.n <= max_public_tier
+        if is_public:
+            available += 1
+            landing.append(f"- ‚úÖ [TIER {t.n} ‚Äî {t.name}](/curriculum/{tier_folder})\n")
+
+    landing.insert(
+        landing.index("## Tiers\n"),
+        f"\n**Available now:** {available} tier(s)"
+        + (f" ‚Ä¢ **Locked:** {locked}" if locked else "")
+        + "\n",
+    )
+
+    write_file(docs_root / "index.mdx", "".join(landing) + "\n")
+        
+    # Tiers + days
+    for t in tiers:
+        tier_cfg = load_tier_config(config_root, t.n)
+        tier_defaults: dict[str, Any] = tier_cfg["tier_defaults"]
+        file_overrides: dict[str, Any] = tier_cfg["files"]
+
+        expected_slugs = {slugify(d.title) for d in t.days}
+        extra = set(file_overrides.keys()) - expected_slugs
+        if extra:
+            raise ValueError(
+                f"{config_root / f'tier-{t.n:02d}.json'} contains unknown slugs: {sorted(extra)}"
+            )
+
+        tier_folder = docs_root / f"tier-{t.n:02d}-{slugify(t.name)}"
+        tier_index_slug = f"/curriculum/{tier_folder.name}"
+
+        write_file(
+            tier_folder / "_category_.json",
+            json.dumps(
+                {
+                    "label": f"TIER {t.n} ‚Äî {t.name}",
+                    "position": t.n,
+                    "link": {
+                        "type": "generated-index",
+                        "slug": tier_index_slug,
+                        "title": f"TIER {t.n} ‚Äî {t.name}",
+                        "description": "Do tasks ‚Üí do boss.",
+                    },
+                },
+                indent=2,
+            )
+            + "\n",
+        )
+
+        for i, d in enumerate(t.days, start=1):
+            slug = slugify(d.title)
+            filename = f"{slug}.md"
+
+            sidebar_label = f"{d.emoji} {d.title}"
+            title = f"{d.emoji} ‚Äî {d.title}"
+
+            effective = merge_section(global_defaults, tier_defaults)
+            effective = merge_section(effective, file_overrides.get(slug, {}))
+
+            # If a block is None or an empty list, we treat it as "do not render".
+            task = effective.get("task")
+            checklist = effective.get(
+                "checklist",
+                ["Works", "Cleaned up", "(Optional) 1 upgrade / stretch"],
+            )
+
+            example_run = effective.get("example_run")
+            solution_block = effective.get("solution_block")
+
+            hints_block = effective.get("hints_block", {})
+            hints_enabled = bool(hints_block.get("enabled", False))
+            hints = effective.get("hints", []) if hints_enabled else []
+
+            if "docs_links" in effective:
+                docs_links = effective["docs_links"]
+            else:
+                docs_links = links_for_tier(t.n)
+
+            path = tier_folder / filename
+            existing = path.read_text(encoding="utf-8") if path.exists() else ""
+            existing = normalize_newlines(existing)
+
+            md = upsert_frontmatter(
+                existing,
+                title=title,
+                sidebar_label=sidebar_label,
+                sidebar_position=i,
+            )
+
+            # Task / Checklist are optional: if they resolve to empty/None, remove the section entirely.
+            if isinstance(task, list) and any(x.strip() for x in task):
+                md = replace_or_append_section(md, "Task", section_body_from_lines(render_bullets(task)))
+            else:
+                md = remove_section(md, "Task")
+
+            if isinstance(checklist, list) and any(x.strip() for x in checklist):
+                md = replace_or_append_section(
+                    md, "Checklist", section_body_from_lines(render_checklist(checklist))
+                )
+            else:
+                md = remove_section(md, "Checklist")
+
+            if hints_enabled:
+                md = replace_or_append_section(md, "Hints", section_body_from_lines(render_bullets(hints)))
+            else:
+                md = remove_section(md, "Hints")
+
+            # Example run (raw markdown lines; not forced into bullets)
+            if isinstance(example_run, list) and any(x.strip() for x in example_run):
+                md = replace_or_append_section(md, "Example run", section_body_from_lines(example_run))
+            else:
+                md = remove_section(md, "Example run")
+
+            # Solution (spoiler)
+            if isinstance(solution_block, dict) and solution_block.get("enabled", True):
+                summary = solution_block.get("summary") or "Show solution"
+                language = solution_block.get("language") or "python"
+                filename = solution_block.get("filename")
+                text_lines = solution_block.get("text") or []
+                code_lines = solution_block.get("code") or []
+
+                body_lines: list[str] = []
+                body_lines.append("<details>")
+                body_lines.append(f"  <summary>{summary}</summary>")
+                body_lines.append("")
+
+                # Optional text block inside the spoiler
+                if isinstance(text_lines, list) and any(x.strip() for x in text_lines):
+                    body_lines.extend(text_lines)
+                    body_lines.append("")
+
+                if isinstance(code_lines, list) and any(x.strip() for x in code_lines):
+                    if isinstance(filename, str) and filename.strip():
+                        body_lines.append(f"```{language} title=\"{filename.strip()}\"")
+                    else:
+                        body_lines.append(f"```{language}")
+                    body_lines.extend(code_lines)
+                    body_lines.append("```")
+
+                body_lines.append("")
+                body_lines.append("</details>")
+
+                # Only render if there's *something* inside.
+                if len(body_lines) > 5:
+                    md = replace_or_append_section(md, "Solution (spoiler)", section_body_from_lines(body_lines))
+                else:
+                    md = remove_section(md, "Solution (spoiler)")
+            else:
+                md = remove_section(md, "Solution (spoiler)")
+
+            if docs_links:
+                md = replace_or_append_section(
+                    md, "Docs / Tutorials", section_body_from_lines(render_docs_links(docs_links))
+                )
+            else:
+                md = remove_section(md, "Docs / Tutorials")
+
+            # Final formatting pass: prevent runaway blank lines from accumulating
+            # after multiple generations.
+            md = re.sub(r"\n{3,}", "\n\n", md).strip("\n") + "\n"
+            write_file(path, md)
+
     return docs_root
\ No newline at end of file
